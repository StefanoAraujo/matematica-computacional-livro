== Cap 1

glkdk

== Vetores

:cap: cap2

.Objetivos do capítulo
____
Ao final deste capítulo você deverá ser capaz de:

* Compreender o conceito de vetores em latexmath:[$\mathbb{R}^n$];
* Familiarizar-se com as operações e  propriedades dos vetores, e aplicar estes resultados nos cálculos que os envolvam;
* Entender os conceitos de produto interno, norma e distância entre vetores;
* Dado um conjunto de vetores em latexmath:[$\mathbb{R}^n$], saber determinar se este é linearmente independente ou não;
* Dado um conjunto de vetores em latexmath:[$\mathbb{R}^n$], saber determinar se este é uma base ou não de latexmath:[$\mathbb{R}^n$];

____


Em diversas aplicações da física surgem grandezas, como por exemplo:
altura, diâmetro, temperatura, etc., as quais são grandezas que  podem
ser representadas na reta real, denotada por latexmath:[$\mathbb{R}$,
e são denominadas de grandezas escalares. Por outro lado, existem
outros tipos de grandezas, como por exemplo: força, velocidade, etc.,
as quais  podem ser representadas por segmentos de reta orientados num
plano, ou seja, além de ter magnitude, tem uma direção apropriada e
partem de um ponto de referência, denotado por ${\bf O}$]. Mais ainda,
existem grandezas que podem ser representadas no espaço. Em geral,
este tipo de elemento é denominado de vetor, e será este o assunto
abordado neste capítulo.


=== Vetores em R²


Começaremos apresentando as operações de soma e multiplicação por um
escalar, entre vetores de latexmath:[$\mathbb{R}^2$].


Adição:: Dados os vetores latexmath:[$u$ e $w\in \mathbb{R}^2$.   A soma dos vetores $u$ e $w$, denotada por $u+w$,  se obtêm pela chamada lei do paralelogramo, isto é, $u+w$ é a diagonal do paralelogramo formado por $u$ e $w$]; veja o item(a) da figura a seguir. 


image::images/cap2/vetores.eps[scaledwidth="82%"]


Multiplicação por um escalar:: Dados um escalar latexmath:[$\alpha \in \mathbb{R}$ e um vetor $u \in \mathbb{R}^2$. A resultante da multiplicação entre $\alpha$ e $u$, denotada por $\alpha u$, se obtêm multiplicando a magnitude de $u$ por $\alpha$, onde  $\alpha u$ preserva a mesma direção que $u$, se $\alpha\geq 0$, ou tem  a direção oposta que $u$, se $\alpha<0$; o item(b) da figura acima, ilustra este fato para $\alpha=2$ e $\alpha=-\frac{6}{5}$]. 

Representando estes vetores no  plano cartesiano, e escolhendo latexmath:[${\bf O}=(0,0)$] como a origem dos eixos coordenados, podemos  determinar cada vetor de forma única pelas coordenadas do seu ponto final. 

[NOTE]
====
Neste livro, identificaremos de agora em diante, um vetor pelo seu ponto final, isto é, o par ordenado latexmath:[$(a,b)\in \mathbb{R}^2$ denotará o vetor com ponto inicial ${\bf O}$ e ponto final $(a,b)$]. 
====

Desta forma, as operações definidas acima podem ser reescritas da seguinte forma:

Adição:: Dados latexmath:[$u=(a,b)$ e $w=(c,d)$, dois  vetores em $\mathbb{R}^2$. Então $(a+c, b+d)=u+w$]; veja o item(a) da figura a seguir.

image::images/cap2/vetores1.eps[scaledwidth="82%"]

Multiplicação por um escalar:: Dados o escalar latexmath:[$\alpha$ e  o vetor $u=(a,b)$. Então $(\alpha a,\alpha b)=\alpha u$]; veja o item(b) da figura anterior.

.{zwsp}
====
Consideremos os seguintes vetores:
[latexmath]
++++
\[
u=(1,-3),\quad v=(5,6)\quad \mbox{e o escalar}\quad \alpha=7.
\]
Ent\~ao
\[
u+v=(1,-3)+(5,6)=(1+5,-3+6)=(6,3).
\]
\[
\alpha \,u=7(1,-3)=(7(1),7(-3))=(7,-21).
\]
\[
\alpha \,v=7(5,6)=(7(5),7(6))=(35,42).
\]
++++
====


=== Vetores em R^n^  

Continuando, as definições de adição e multiplicação são generalizadas em latexmath:[$\mathbb{R}^n$, com a $n$-upla ordenada $(u_1,u_2,\ldots, u_n)$ denotando um vetor em $\mathbb{R}^n$, com ponto inicial ${\bf O}$ e ponto final $(u_1,u_2,\ldots, u_n)$].

Definição 2.1:: 

... Uma latexmath:[$n$-upla, é denotada por $u=(u_1,u_2,\ldots, u_n)$] e chamada de *vetor* ou *ponto* ; 
... O conjunto de todas as latexmath:[$n$-uplas de números reais,  é denominado de $n$]-espaço e é denotado por latexmath:[$\mathbb{R}^n$];
... Os números reais latexmath:[$u_i$ se chamam de {\bf coordenadas} ou {\bf componentes} do vetor $u$].

[IMPORTANT]

Quando trabalhamos com o espaço latexmath:[$\mathbb{R}^n$, usamos o termo escalar para os elementos de $\mathbb{R}$].


.{zwsp}
====
Consideremos os seguintes vetores:
[latexmath]
++++
\[
(1,0),\quad (-2, 5), \quad \left(1,\sqrt{2}, \frac{1}{5}, 9, 0\right), \quad \mbox{e}\quad \left(-1,-2,-\pi,-\sqrt{3}, 10000\right).
\]
++++
Os dois primeiros vetores tem duas componentes, logo pertencem a  latexmath:[$\mathbb{R}^2$, enquanto que os dois últimos vetores tem cinco componentes, logo pertencem a  $\mathbb{R}^5$].
====

Definição 2.2:: Sejam os vetores latexmath:[$u=(u_1,u_2,\ldots, u_n)$ e $w=(w_1,w_2,\ldots, w_n) \in \mathbb{R}^n$. Diz-se que $u$ e $w$ são {\bf iguais}, e se denota  $u=w$], se suas coordenadas correspondentes são iguais, isto é, 
[latexmath]
++++
\[
u_1 = w_1,\,\, u_2=w_2,\ldots, \,\, u_n=w_n.
\]
++++

.{zwsp}
==== 
.. Os vetores latexmath:[$u=-3(\frac{1}{3}, -2)$ e $v=(-1, 6)$ de $\mathbb{R}^2$] são iguais.

.. Os vetores latexmath:[$u=(1,3,5)$ e $w=(3,5,1)$ de $\mathbb{R}^3$] não são iguais, devido que nenhuma das componentes correspondentes são iguais.

.. Se  latexmath:[$(x-1,y-2, z-3)=(3,2,1)$], então por igualdade de vetores temos que
+
[latexmath]
++++
\[
x-1=3,\quad  y-2=2\quad\mbox{e}\quad z-3=1.
\]
++++
+
Resolvendo cada igualdade temos que latexmath:[$x=4$, $y=4$, $z=4$].  
====



==== Adição de vetores e multiplicação por um escalar

Definição 2.3:: Sejam os vetores 
+
[latexmath]
++++
\[
u=(u_1,u_2,\ldots, u_n)\quad \mbox{e} \quad w=(w_1,w_2,\ldots, w_n)\in \mathbb{R}^n.
\]
++++
+
Então, 
--
... a *adição* de latexmath:[$u$ e $w$, denotada por $u+w$], é o vetor que se obtêm somando coordenada a coordenada:
+
[latexmath]
++++
\[
u+w = (u_1+w_1,u_2+w_2,\ldots, u_n+w_n);
\]
++++
... a *multiplicação* de um número latexmath:[$\alpha\in \mathbb{R}$ pelo vetor $u$, denotada por $\alpha u$, é o vetor que se obtêm multiplicando cada coordenada de $u$ por $\alpha$]:
+
[latexmath]
++++
\[
\alpha u=(\alpha u_1,\alpha u_2,\ldots, \alpha u_n).
\]
++++
... o *vetor nulo* em latexmath:[$\mathbb{R}^n$, denotado por ${\bf 0}$], é definido por
+
[latexmath]
++++
\[
{\bf 0}= (0,0,\ldots, 0);
\]
além disso, para qualquer vetor $u \in \mathbb{R}^n$, temos que
\[
u+{\bf 0} = (u_1+0,u_2+0,\ldots, u_n+0)= (u_1,u_2,\ldots, u_n)=u={\bf 0}+u.
\]
++++
--

[NOTE]
====
Dados latexmath:[$u$ e $w$  em $\mathbb{R}^n$]. Então

.. latexmath:[$u+w$ e $\alpha u$ são também vetores em $\mathbb{R}^n$]; 
.. latexmath:[$\,$]
+
[latexmath]
++++
\[
-u=-1\,u\quad \mbox{e}\quad u-w=u+(-w);
\]
++++
.. A  adição de vetores com diferente número de componentes não está definida.
====

.{zwsp}
====
Sejam latexmath:[$u=(1,2,3,4)$ e $w=(6,7,-1,3)$ vetores em $\mathbb{R}^4$]. Então:

[latexmath]
++++
\[
\begin{array}{rcl}
u+w &=& (1,2,3,4) +  (6,7,-1,3) = (1+6, 2+7, 3+(-1), 4+3) = (7,9,2,7) ;\\
\\
-2u &=&  -2 (1,2,3,4) =  (-2(1), -2(2), -2(3), -2(4))= (-2,-4, -6, -8) ;\\
\\
3u-4w &=&3u+(-4w)\\
	&=& 3(1,2,3,4) - 4(6,7,-1,3)\\
      &=& (3(1),3(2),3(3),3(4)) + ((-4)6,(-4)7,(-4)(-1),(-4)3)\\
&=& (3,6,9,12)+ (-24,-28, 4, -12)\\
&=& (3+(-24),6+(-28),9+4,12+(-12))= (-21, -22, 13, 0).
\end{array}
\]
++++
====

A seguir resumiremos as propriedades básicas das operações de adição de vetores e multiplicação de um vetor por um escalar   em latexmath:[$\mathbb{R}^n$].

Teorema 2.1:: Sejam os vetores latexmath:[$u,v,w\in \mathbb{R}^n$ e os escalares $\alpha, \beta \in \mathbb{R}$]. Então
+
--
... latexmath:[$(u+v)+w=u+(v+w)$];
... latexmath:[$u+{\bf 0}=u $];
... latexmath:[$u+(-u)={\bf 0}$];
... latexmath:[$u+v = v+u$];
... latexmath:[$\alpha(u+v)= \alpha u + \alpha v $];
... latexmath:[$(\alpha + \beta)u= \alpha u + \beta u$];
... latexmath:[$(\alpha \beta)u = \alpha (\beta u)$];
... latexmath:[$ 1\,u=u $].
--

[IMPORTANT]
====
Sejam latexmath:[$u$ e $w$ vetores em $\mathbb{R}^n$, tal que $u=\alpha w$, para algum escalar não nulo $\alpha\in \mathbb{R}$]. Então:

.. Se latexmath:[$\alpha>0$, diz-se que $u$ tem a {\bf mesma direção} de $w$];
 
.. Se latexmath:[$\alpha<0$, diz-se que $u$ tem a {\bf direção oposta} de $w$].
====


==== Produto interno

A seguir definiremos um novo tipo de produto, denominado de produto escalar ou produto interno, entre dois vetores em latexmath:[$\mathbb{R}^n$]. Este conceito é  importante para o bom entendimento dos próximos capítulos.


Definição 2.4:: Sejam os vetores 
+
[latexmath]
++++
\[
u=(u_1,u_2,\ldots, u_n)\quad \mbox{e} \quad w=(w_1,w_2,\ldots, w_n)\in \mathbb{R}^n.
\]
++++
+
Então, 
+
--
... O *produto interno* de latexmath:[$u$ e $w$, denotado por $u\cdot w$], é o escalar que se obtêm multiplicando as componentes correspondentes dos vetores e, logo depois, somando os produtos resultantes, isto é:
+
[latexmath]
++++
\[
u\cdot w = u_1w_1 +u_2 w_2+ \cdots + u_n w_n = \sum\limits^{n}_{i=1} u_i w_i;
\]
++++

... diz-se que os vetores latexmath:[$u$ e $w$] são *ortogonais* ou *perpendiculares*, se seu produto interno é igual a zero, isto é: 
+
[latexmath]
++++
\[
u \cdot w =0.
\]
++++
--


.{zwsp}
====
Sejam latexmath:[$u=(1,2, 3)$, $v=(6,7,1)$ e $w=(4,-5,2)$]. Então
[latexmath]
++++
\[
\begin{array}{cclclcl}
u \cdot v &=& (1)(6)+(2)(7)+ (3)(1)&=& 6+14+3&=&23; \\
v \cdot w &=& (6)(4)+(7)(-5)+(1)(2)&=&24-35+2&=&-8;\\
u \cdot w &=& (1)(4)+(2)(-5)+ (3)(2)&=& 4-10+6 &=&0. 
\end{array}
\]
++++
Portanto, do item ii da definição acima, latexmath:[$u$ e $v$ não são ortogonais, $v$ e $w$ não são ortogonais e, $u$ e $w$] são ortogonais.
====




As propriedades básicas do produto interno em latexmath:[$\mathbb{R}^n$] são apresentadas no seguinte resultado.

Teorema 2.2:: Para todo vetor latexmath:[$u,v,w\in \mathbb{R}^n$ e todo escalar $\alpha \in \mathbb{R}$]:

... latexmath:[$(u+v)\cdot w=u\cdot w +v\cdot w$];
... latexmath:[$(\alpha u) \cdot v=\alpha (u\cdot v)$]
... latexmath:[$u\cdot v = v\cdot u$];
... latexmath:[$u\cdot u \geq 0$];
... latexmath:[$u\cdot u =0 \,\Leftrightarrow\, u=0$].

[NOTE]
O espaço latexmath:[$\mathbb{R}^n$ munido com as operações de adição, multiplicação por um escalar e produto interno é conhecido como o $n$]*-espaço euclidiano*.

==== Norma e distância em R^n^


Definição 2.5:: Sejam os vetores 
+
[latexmath]
++++
\[
u=(u_1,u_2,\ldots, u_n)\quad \mbox{e} \quad w=(w_1,w_2,\ldots, w_n)\in \mathbb{R}^n.
\]
++++
+
Então, 
+
--
... a *norma* de latexmath:[$u$, denotada por $\| u\|$ , é definida como a raíz quadrada não negativa do produto interno $u\cdot u$]:
+
[latexmath]
++++
\[
\| u\|=  \sqrt{u\cdot u} = \sqrt{u_1^2 + u_2^2 + \cdots + u_n^2} = \sqrt{\sum\limits^{n}_{i=1} u_i^2 };
\]
++++

... a *distância* entre latexmath:[$u$ e $w$, denotada por $d(u,w)$], é definida por:
+
[latexmath]
++++
\[
d(u,w)= \sqrt{(u_1 -w_1)^2 + (u_2 -w_2)^2 + \cdots + (u_n -w_n)^2} = \sqrt{\sum\limits^{n}_{i=1} (u_i -w_i)^2 };
\]
++++
... diz-se que latexmath:[$u \in \mathbb{R}^n$] é um *vetor unitário* se a norma deste é 1, isto é:
+
[latexmath]
++++
\[
\|u\|=1.
\]
++++
--

.{zwsp}
====
Sejam latexmath:[$u=(1,-2,3)$ e $w=(5,1,-2)$]. Então
[latexmath]
++++
\[
\|u\|  = \sqrt{(1)^2 + (-2)^2 + (3)^2}= \sqrt{14};
\]
\[
\|w\|  = \sqrt{(5)^2 + (1)^2 + (-2)^2}= \sqrt{30};
\]
\[
d(u,w) = \sqrt{(1-5)^2 + (-2-1)^2 + (3-(-2))^2}= \sqrt{40}.
\]
Além disso, já que 
\[
\|u\|\neq 1\quad\mbox{e}\quad\|w\|\neq 1
\]
++++
estes vetores não são unitários.

====

[NOTE]
====
Dados os vetores latexmath:[$u$ e $w$ em $\mathbb{R}^n$], temos que:

.. latexmath:[$d(u,w)= \|u-w \|$];
.. latexmath:[$d(u,{\bf 0})= \|u \|$];
.. Se latexmath:[$u\neq {\bf 0}$, então o vetor $\overline{u}$] definido por
+
[latexmath]
++++
\[
\overline{u}:=\frac{u}{\|u\|}
\]
++++
+
é um vetor unitário, e tem a mesma direção de latexmath:[$u$];

.. Do item ii da definição acima, temos que latexmath:[$d(u,w)= d(w,u)$].
====


[IMPORTANT]
====
A norma definida no item i da *Definição 2.5*, é conhecida como latexmath:[$\|\cdot\|_2$. Embora que, neste livro somente trabalharemos com esta norma em $\mathbb{R}^n$], a definição formal é dada a seguir.

Uma *norma vetorial* em latexmath:[$\mathbb{R}^n$ é uma aplicação, denotada por $\|\cdot \|$], tal que:

[latexmath]
++++
\[
\begin{array}{rccc}
\|\cdot\|:&\mathbb{R}^n &\longrightarrow& \mathbb{R}\\
&u&\longmapsto& \|u\|
\end{array}
\]
++++

satisfaz às seguintes condições:

... latexmath:[$\|u\|\geq 0$, $\forall\, u \in \mathbb{R}^n$  e $\|u\|=0 \Leftrightarrow u=0$];

... latexmath:[$\|\alpha u\|=|\alpha|\|u\|$, $\forall\, \alpha \in \mathbb {R}$ e $\forall\, u \in \mathbb{R}^n$];

... latexmath:[$\|u+v\|\leq \|u\|+\|v\|$, $\forall\, u$ e $v \in \mathbb{R}^n$].

Assim, temos as seguintes normas em latexmath:[$\mathbb{R}^n$]:

Norma 1:: latexmath:[$\,$]
[latexmath]
++++
\[
\|u\|_1=\sum\limits_{i=1}^{n}|u_{i}|.
\] 
++++

Norma Infinito:: latexmath:[$\,$]
[latexmath]
++++
\[
\|u\|_\infty=\max\limits_{1\leq i\leq n}|u_{i}|.
\] 
++++

Norma p:: latexmath:[$\,$]
[latexmath]
++++
\[
\|u\|_p=\left({\sum\limits_{i=1}^{n}(u_i)^p}\right)^{\frac{1}{p}}, \qquad 1\leq p\leq \infty.
\] 
++++

====


As propriedades vistas no *Teorema 2.2*, sobre o produto interno, implicam nas seguintes propriedades da norma.

Teorema 2.3:: Para todo vetor latexmath:[$u,\,w\in \mathbb{R}^n$ e todo escalar $\alpha \in \mathbb{R}$]:

... latexmath:[$\|u\|>0$, se $u\neq {\bf 0}$];
... latexmath:[$\|u\|=0$, se $u= {\bf 0}$]; 
... latexmath:[ $\|\alpha u \| = |\alpha| \|u\|$];
... latexmath:[$\|u+w\| \leq \|u\|+ \|w\|$].

[NOTE]
====
.. O item iv do teorema acima é conhecido, na literatura, como a *Desigualdade Triangular*.

.. Se consideramos, em particular,  latexmath:[$\mathbb{R}^2$ e os pontos $p=(a,b)$ e $q=(c,d)$], temos que
+
[latexmath]
++++
\[
\|p\|=\sqrt{a^2+b^2},\qquad \mbox{e}\qquad d(p,q)=\sqrt{(a-c)^2 + (b-d)^2}.
\]
++++
+
Em outras palavras, latexmath:[$\|p\|$ corresponde à magnitude do segmento de reta que vai desde a origem até o ponto $p$ e $d(p,q)$ corresponde à distância entre os pontos $p$ e $q$. O item(a) e item(b) da figura a seguir ilustram  $\|p\|$ e $d(p,q)$], respectivamente. 
+
image::images/cap2/norma1.eps[scaledwidth="80%"]
====





Com a teoria estudada até o momento, estamos prontos para mostrar uma interpretação geométrica do produto interno de dois vetores em latexmath:[$\mathbb{R}^2$. O item(a) da figura a seguir, mostra dois vetores não nulos $u$ e $w$, formando entre si um ângulo $\theta \in (0,\frac{\pi}{2})$. Por outro lado, no item(b) temos três vetores, o mesmo vetor $u$ e dois vetores ortogonais $p$ e $q$,  cuja soma resulta em $u$, ainda mais, $q=\alpha w$, desde que $0< \theta < \frac{\pi}{2}$, $\alpha>0$].  

image::images/cap2/norma2.eps[scaledwidth="80%"]



O seguinte resultado é uma relação fundamental na teoria de vetores, conhecida na literatura como a *desigualdade de Cauchy-Schwarz*.

Teorema 2.4 (Teorema de Cauchy-Schwarz):: Sejam latexmath:[$u,w\in \mathbb{R}^n$]. Então, 
[latexmath]
++++
\[
|u\cdot w|\leq \|u\| \|w\|.
\]
++++

[IMPORTANT]
====
Da desigualdade de *Cauchy-Schwarz*, obtemos que
[latexmath]
++++
\[
-1\leq \frac{u\cdot w}{\|u\|\|w\|} \leq 1.
\]
++++
O que pela sua vez implica na existência de um único número real latexmath:[$\theta \in [0,\pi\]$] tal que:
[latexmath]
++++
\[
\cos(\theta)= \frac{u\cdot w}{\| u\| \|w\|}.
\]
++++
====


Definição 2.6:: Sejam latexmath:[$u,w\in \mathbb{R}^n$, tais que $w\neq {\bf 0}$]. 

... O vetor *projeção* de latexmath:[$u$ sobre $v$, é definido por $\alpha w$], onde 
+
[latexmath]
++++
\[
\alpha=\frac{u\cdot w}{\|u\| \|w\|};
\]
++++

... Se latexmath:[$u$ e $w$ são ambos não nulos, o {\bf ângulo} $\theta$ entre os vetores $u$ e $w$] é definido 
+
[latexmath]
++++
\[
\theta= \arccos \left( \frac{u\cdot w}{\| u\| \|w\|} \right).
\]
++++

[NOTE]
====
.. A função latexmath:[${\rm arcocosseno}$ restringe $\theta$ ao intervalo $[0, \pi\]$];
.. Se latexmath:[$u\cdot w =0$, então $\theta = \frac{\pi}{2}$] (ou latexmath:[$\theta= 90^{\circ}$]) o qual coincide com a definição de ortogonalidade.
====


==== Vetores coordenados unitários

Definição 2.7:: Seja o vetor latexmath:[$e_i $ em $\mathbb{R}^n$], definido por: 
+
[latexmath]
++++
\[
e_i=(0,\ldots,0,1,0,\ldots, 0)
\]
++++
+
onde a latexmath:[$i$-ésima componente de $e_i$ é $1$] e todas as outras componentes são zero.
+
--

... latexmath:[$e_i$ é chamado de $i$]*-ésimo vetor coordenado unitário*;

... os latexmath:[$n$] vetores: 
+
[latexmath]
++++
\[
e_1=(1,0,\ldots,0),\quad e_2=(0,1,\ldots,0), \ldots,e_n=(0,0,\ldots,1)
\]
++++
+
são chamados de *vetores coordenados unitários*.
--

.{zwsp}
====
.. Em latexmath:[$\mathbb{R}^3$] temos os seguintes vetores coordenados unitários:
+
[latexmath]
++++
\[
e_1=(1,0,0),\quad e_2=(0,1,0)\quad \mbox{e}\quad e_3=(0,0,1).
\]
++++
.. Em latexmath:[$\mathbb{R}^5$] temos os seguintes vetores coordenados unitários:
+
[latexmath]
++++
\[
e_1=(1,0,0,0,0),\quad e_2=(0,1,0,0,0),\quad e_3=(0,0,1,0,0),\atop e_4=(0,0,0,1,0)\quad \mbox{e}\quad e_5=(0,0,0,0,1).
\]
++++

====

[IMPORTANT]
====
.. O termo de ``vetor coordenado unitário'' provém do fato de cada vetor latexmath:[$e_i$] ter norma 1 isto é,
+
[latexmath]
++++
\[
\|e_i\|=1\quad \forall\,i=1,2,\dots,n.
\]
++++

.. Todos os vetores coordenados unitários são ortogonais entre si, isto é, o produto interno de qualquer par de vetores é zero:
+
[latexmath]
++++
\[
e_i \cdot e_j =0, \qquad \mbox{se}\quad i\neq j;
\] 
++++

====

Assim obtemos o seguinte resultado


Teorema 2.5:: Todo vetor latexmath:[$u=(u_1,u_2,\ldots, u_n)\in \mathbb{R}^n$] pode ser expresso da forma:
+
[latexmath]
++++
\[
\begin{array}{rclcl}
u &=& u_1 e_1+ u_2e_2+ \cdots +u_i e_i + \cdots + u_n e_n &=& \sum\limits_{k=1}^{n} u_n e_n.
\end{array}
\]
Além disso, esta representação é única, isto é, se
\[
u= \sum\limits_{k=1}^{n} u_k e_k \quad \mbox{e} \quad u= \sum\limits_{k=1}^{n} w_k e_k,
\]
++++
+
então latexmath:[$u_k=w_k$ para cada $k=1,2,\ldots,n$].

Na seguinte figura vemos uma ilustração deste fato para latexmath:[$n=3$].

image::images/cap2/vetores3.eps[scaledwidth="60%"]

Definição 2.8:: Dados latexmath:[$w_1,w_2,\ldots,w_n$ vetores em $\mathbb{R}^n$. Denomina-se {\bf combinação linear} dos vetores $w_1,w_2,\ldots,w_n$] à soma da forma 
+
[latexmath]
++++
\[
\alpha_1 w_1+ \alpha_2 w_2+\cdots + \alpha_n w_n      =\sum\limits^{n}_{i=1} \alpha_i w_i,
\]
++++
+
onde latexmath:[$\alpha_i\in \mathbb{R}$ para todo $i=1,\ldots,n$]. 

[NOTE]
====
Do Teorema anterior temos que qualquer vetor de latexmath:[$\mathbb{R}^n$ pode ser expresso como uma combinação linear dos vetores coordenados unitários, $e_1,e_2,\ldots, e_n$, ou seja, os vetores coordenados unitários ``geram'' $\mathbb{R}^n$. Existem em $\mathbb{R}^n$ outros conjuntos, de $n$ vetores, diferentes dos $e_1,e_2,\ldots, e_n$, que também geram $\mathbb{R}^n$].

====

==== Envoltória linear de um conjunto finito de vetores


Definição 2.9::  Sejam latexmath:[$S=\{u_1,u_2,\ldots, u_k\}$ um conjunto de $k$ vetores de $\mathbb{R}^n$ e $w \in \mathbb{R}^n$, onde $k$ pode ser menor ou igual, ou maior, que a dimensão do espaço $\mathbb{R}^n$, ou seja,  $k\leq n$ ou $k> n$]. 
+
--

... Se latexmath:[$w$ é representado como uma combinação linear dos $u_1,u_2,\ldots, u_k$], isto é
+
[latexmath]
++++
\[
w= \alpha_1 u_1+ \alpha_2 u_2+\cdots + \alpha_k u_k = \sum\limits^{k}_{i=1} \alpha_i u_i,
\]
++++
+
para alguns escalares latexmath:[$\alpha_1, \alpha_2,\ldots,\alpha_k \in \mathbb{R}$, então diz-se que $S$ {\bf gera o vetor} $w$].

... O conjunto de todos os vetores gerados por latexmath:[$S$ é denominado a {\bf envoltória linear} de $S$ e é denotado por $L(S)$].

... Diz-se que latexmath:[$S$ {\bf gera o espaço} $\mathbb{R}^n$ se $L(S)=\mathbb{R}^n$].
--

[NOTE]
A envoltória linear de latexmath:[$S$ é o conjunto de todas as possíveis combinações lineares de vetores em $S$].

.{zwsp}
====
.. Seja latexmath:[$S=\{u\}$. Então a envoltória linear de $S$] é:
+
[latexmath]
++++
\[
L(S) = \{ \lambda u\,:\, \lambda\in \mathbb{R}  \}.
\]
++++
.. Seja latexmath:[$S=\{u,v\}$. Então a envoltória linear de $S$] é:
+
[latexmath]
++++
\[
L(S) = \{ \lambda\, u+\beta\,v\,:\, \lambda,\,\,\beta\in \mathbb{R}  \}.
\]
++++
.. Seja latexmath:[$S=\{u,-u\}$. Então a envoltória linear de $S$] é:
+
[latexmath]
++++
\[
L(S) = \{ \lambda\, u+\beta\,(-u)\,:\, \lambda,\,\,\beta\in \mathbb{R}  \}=\{ (\lambda-\beta) u\,:\, \lambda,\,\,\beta \in \mathbb{R}  \}.
\]
Fazendo $\gamma=\lambda-\beta$, temos que 
\[
L(S) =\{ \gamma u\,:\, \gamma\in \mathbb{R}  \}
\]
++++
====

[NOTE]
====
O vetor nulo latexmath:[${\bf 0}$ pode ser gerado por qualquer conjunto $S=\{u_1,u_2,\ldots, u_k  \}$], pois:
[latexmath]
++++
\[
{\bf 0}= 0u_1 +0u_2 + \cdots + 0u_k.
\]
++++
A representação, latexmath:[$\alpha_1=0$, $\alpha_2=0,\ldots$, $\alpha_k=0$], é denominada de *representação trivial* do vetor nulo. Porém, podem existir combinações lineares não triviais que representem o vetor nulo. De fato, se latexmath:[$u_2=3u_1$, então obtemos infinitas representações não triviais do ${\bf 0}$]:
[latexmath]
++++
\[
{\bf 0}= 3\lambda u_1 - \lambda u_2+ 0u_3+\cdots +0u_k, \qquad \mbox{para qualquer}\quad \lambda\in \mathbb{R}.
\]
++++

====

Agora vamos focar nossa atenção nos conjuntos latexmath:[$S$] que geram os vetores de forma única. 

Definição 2.10:: Sejam o conjunto latexmath:[$S=\{u_1,u_2,\ldots,u_k\}$ de vetores de $\mathbb{R}^n$  e $w\in \mathbb{R}^n$. Diz-se que $S$ gera o vetor $w$] de forma única se:

... latexmath:[$S$ gera $w$];  
... latexmath:[$w=\sum\limits^{k}_{i=1}\alpha_i u_i$ e $w=\sum\limits^{k}_{i=1}\beta_i u_i$ implica que $\alpha_i = \beta_i$ para todo $i=1,\dots,k$].

.{zwsp}
====
.. Seja o conjunto latexmath:[$S=\{(1,0),(0,1),(1,1)\}$ e $w=(2,2)$]. Então, temos que
+
[latexmath]
++++
\[
w=2(1,0)+2(0,1)+0(1,1),
\]
ou seja, $w$ é gerado por $S$.
Porém, também temos que
\[
w=0(1,0)+0(0,1)+2(1,1).
\]
++++
+
Portanto, latexmath:[$w$ não  é gerado de forma única por $S$].

.. Seja o conjunto latexmath:[$\overline{S}=\{(1,0),(0,1)\}$ e $w=(2,2)$]. Então, temos que
+
[latexmath]
++++
\[
w=2(1,0)+2(0,1),
\]
++++
+
ou seja, latexmath:[$w$ é gerado por $\overline{S}$. Além disso, não existe nenhuma outra combinação em $\overline{S}$ que gere $w$].
+
Portanto, latexmath:[$w$ é gerado de forma única por $\overline{S}$].

====


Teorema 2.6:: Seja um conjunto latexmath:[$S\subset \mathbb{R}^n$. Então, os vetores de $L(S)$ são gerados de forma única por $S$ se, e somente se, $S$] gera de forma única o vetor nulo.

.{zwsp}
====
.. Seja o conjunto latexmath:[$S=\{(1,0),(0,1),(1,1)\}$]. Então, temos que
+
[latexmath]
++++
\[
0=1(1,0)+1(0,1)-1(1,1),
\]
ou seja, $0$ é gerado por $S$.
Porém, também temos que
\[
w=-2(1,0)+-2(0,1)+2(1,1).
\]
++++
+
Assim, latexmath:[$0$ não  é gerado de forma única por $S$. Portanto, segundo o teorema acima, existem vetores em $L(S)$] que não são gerados de forma única.

.. Seja o conjunto latexmath:[$\overline{S}=\{(1,0),(0,1)\}$]. Então, temos que
+
[latexmath]
++++
\[
0=0(1,0)+0(0,1).
\]
++++
+
ou seja, latexmath:[$0$ é gerado por $\overline{S}$. Além disso, não existe nenhuma outra combinação em $\overline{S}$ que gere $0$]. Assim, latexmath:[$0$ é gerado de forma única por $\overline{S}$. Portanto, segundo o teorema acima, todos os  vetores em $L(\overline{S})$] são gerados de forma única.

====

==== Independência linear
O teorema anterior, mostra a importância dos conjuntos de vetores que geram de forma única o vetor nulo, tais conjuntos são de especial distinção, por esse motivo este é o assunto bordado a seguir.

Definição 2.11:: Seja latexmath:[$S=\{u_1, u_2,\ldots, u_k\}\subset \mathbb{R}^n$. Se $S$ gera de forma única o vetor ${\bf 0}$, então se diz que $S$] é um conjunto de vetores *linearmente independente*. Caso contrário, se diz que é *linearmente dependente*. Em outras palavras:
+
--
... a *independência linear* significa que latexmath:[$S$] gera o vetor nulo de forma única, com a representação trivial, isto é,
+
[latexmath]
++++
\[
\mbox{se}\quad  \sum\limits^{k}_{i=1}\alpha_i u_i={\bf 0} \qquad \mbox{implica que} \qquad \alpha_i = 0, \quad \forall i=1,\ldots, k;
\]
++++
... a *dependência linear* significa que latexmath:[$S$] gera o vetor nulo de forma não trivial, isto é,
+
[latexmath]
++++
\[
\mbox{existem}\quad \beta_1,\ldots,\beta_k\in \mathbb{R} \quad \mbox{não todos nulos}:\quad \sum\limits^{k}_{i=1}\beta_i u_i={\bf 0}. 
\]
++++
--

.{zwsp}
====
Segundo o exemplo anterior temos que:

.. O conjunto latexmath:[$S=\{(1,0),(0,1),(1,1)\}$] é um conjunto de vetores linearmente dependente;
.. O conjunto latexmath:[$\overline{S}=\{(1,0),(0,1)\}$] é um conjunto de vetores linearmente independente.

====

[IMPORTANT]
====
.. Por convenção, o conjunto vazio é linearmente independente;

.. Os vetores coordenados unitários latexmath:[$e_1,e_2,\ldots, e_n$ de $\mathbb{R}^n$, geram o vetor ${\bf 0}$, de forma única, assim $S=\{e_1,e_2,\ldots, e_n\}$] é linearmente independente.

.. Qualquer conjunto de vetores que contém o vetor nulo é linearmente dependente. De fato, se latexmath:[$S=\{u_1={\bf 0}, u_2, \ldots, u_k \}$], temos que o nulo possui uma representação não trivial:
+
[latexmath]
++++
\[
{\bf 0}= (2)u_1+ 0u_2+\cdots +0u_k= (2){\bf 0}+ 0u_2+\cdots +0u_k. 
\]
++++
====

.{zwsp}
====
Se consideramos o conjunto latexmath:[$S=\{(1,0), (0,1), (1,1)\}$ de vetores de $\mathbb{R}^2$, temos que $S$] é linearmente dependente. De fato, o vetor nulo pode ser gerado de forma não trivial:
[latexmath]
++++
\[
{\bf 0}=1(1,0) + 1(0,1)+(-1)(1,1).
\]
++++

==== 


O próximo resultado estabelece que, se dado um conjunto latexmath:[$S$ adicionamos a este qualquer vetor da envoltória linear de $S$, $L(S)$], obteremos um conjunto linearmente dependente.

Teorema 2.7:: Seja latexmath:[$S=\{u_1, u_2,\ldots, u_k\}$ um conjunto linearmente independente de $k$ vetores de $\mathbb{R}^n$, e seja $L(S)$ a envoltória linear de $S$. Então, qualquer subconjunto de $k+1$ vetores de $L(S)$] é linearmente dependente.

No próximo resultado, veremos a relação entre o conceito de ortogonalidade e a independência linear.


Definição 2.12:: Dado um conjunto de vetores latexmath:[$S=\{u_1, u_2,\ldots, u_k\}$ de  $\mathbb{R}^n$]. Diz-se que:

... latexmath:[$S$] é *ortogonal* se 
+
[latexmath]
++++
\[
u_i \cdot u_j =0\quad \mbox{para todo}\quad i\neq j.
\]
++++
+
Isto é, dois vetores diferentes quaisquer de um conjunto ortogonal são perpendiculares.

... latexmath:[$S$ é {\bf ortonormal}, se $S$ é ortogonal  e  cada um dos vetores $u_i$] são unitários, isto é,
+
[latexmath]
++++
\[
\|u_i\|=1\quad \mbox{para todo}\quad i=1,\ldots,k.
\]
++++


[IMPORTANT]
====
O conjunto dos vetores latexmath:[$S=\{e_1, e_2, \ldots, e_n\}$] é um conjunto ortonormal.
====


.{zwsp}
====
.. O conjunto latexmath:[$S:=\{(-1,2), (4,2)\}$] é um conjunto ortogonal;

.. Para qualquer latexmath:[$\theta \in \mathbb{R}$] se verifica que:
+
[latexmath]
++++
\[
{\rm sen}^2\theta + {\rm cos}^2 \theta=1.
\]
++++
+
Assim, o conjunto latexmath:[$S:=\left\{ (\cos \theta, {\rm sen} \theta), (-{\rm sen} \theta,\cos \theta )\right\}$] é um conjunto ortonormal, para qualquer latexmath:[$\theta$];


.. O conjunto latexmath:[$S:=\left\{ \left(\frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}} \right), \left(-\frac{2}{\sqrt{6}},\frac{1}{\sqrt{6}},\frac{1}{\sqrt{6}} \right), \left(0,-\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}} \right)\right\}$] é um conjunto ortonormal.

====



Teorema 2.8:: Se latexmath:[$S=\{u_1, u_2,\ldots, u_k\}$ é um conjunto ortogonal de $k$ vetores não nulos de $\mathbb{R}^n$, então $S$] é linearmente independente. Além disso, 
+
--
... se latexmath:[$w\in \mathbb{R}^n$ é gerado por $S$], isto é:
+
[latexmath]
++++
\[
w=\sum\limits^{k}_{i=1}\alpha_i u_i, 
\]
então os escalares $\alpha_i$ são dados por:
\[
\alpha_i=\dfrac{w\cdot u_i}{\|u_i\|^2} \qquad \forall\,\, i=1,2,\ldots,k;
\]
++++
... se latexmath:[$S$ é um conjunto ortonormal, então cada $\alpha_i$] reduz a:
[latexmath]
++++
\[
\alpha_i= w\cdot u_i\qquad \forall\,\, i=1,2,\ldots,k.
\]
++++
--

==== Bases

Devido à importância de estudar os conjuntos de vetores do latexmath:[$\mathbb{R}^n$ que geram qualquer vetor de $\mathbb{R}^n$, de forma única. Introduzimos nesta seção a definição de uma {\bf base} em  $\mathbb{R}^n$]. 

Definição 2.13:: Seja o conjunto latexmath:[$S=\{u_1, u_2,\ldots,u_n\}$ de vetores de $\mathbb{R}^n$. Se $S$ gera qualquer vetor em $\mathbb{R}^n$ de forma única, então diz-se que $S$ é uma {\bf base} em $\mathbb{R}^n$. Além disso, se $S$ é ortogonal, então diz-se que $S$] é  uma *base ortogonal*. Em outras palavras, uma base é um conjunto linearmente independente que gera todo o espaço latexmath:[$\mathbb{R}^n$]. 


[IMPORTANT]
====
O conjunto de vetores coordenados unitários latexmath:[$\{e_1,e_2,\ldots, e_n\}$ de $\mathbb{R}^n$ é uma base para $\mathbb{R}^n$. Mais ainda, desde que $\|e_i\|=1$, para todo $i=1,\dots,n$], esta base também é uma base ortogonal.
====

.{zwsp}
====
.. O conjunto ortogonal latexmath:[$S:=\{(-1,2), (4,2)\}$ é uma base de $\mathbb{R}^2$];

.. O conjunto ortonormal latexmath:[$S:=\left\{ (\cos \theta, {\rm sen} \theta), (-{\rm sen} \theta,\cos \theta )\right\}$ é uma base ortogonal de $\mathbb{R}^2$], para qualquer latexmath:[$\theta$];


.. O conjunto ortonormal latexmath:[$S:=\left\{ \left(\frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}} \right), \left(-\frac{2}{\sqrt{6}},\frac{1}{\sqrt{6}},\frac{1}{\sqrt{6}} \right), \left(0,-\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}} \right)\right\}$ é uma base ortogonal de $\mathbb{R}^3$].

====


O seguinte resultado, afirma que qualquer base de um espaço de dimensão latexmath:[$n$, contém $n$] elementos.


Teorema 2.9:: Dado latexmath:[$\mathbb{R}^n$. Então, as bases que geram $\mathbb{R}^n$] tem as seguintes propriedades:

... Toda base tem exatamente latexmath:[$n$] vetores;
... Qualquer conjunto de vetores linearmente independentes é um subconjunto de uma certa base;
... Qualquer conjunto de latexmath:[$n$] vetores linearmente independente é uma base.




=== Recapitulando

Neste capítulo, abordamos as noções básicas e necessárias sobre *vetores* em latexmath:[$\mathbb{R}^n$], já que esta teoria é fundamental para o bom entendimento deste livro. Em primeiro lugar, apresentamos o conceito de vetores em  latexmath:[$\mathbb{R}^2$], e logo depois, em latexmath:[$\mathbb{R}^n$]. Assim como, as *operações* e *propriedades* relativas a estes. 

Desta forma, nas seções deste capítulo, fomos estudando os conceitos de *produto interno*, *norma* e *distância* entre vetores; foram também apresentados diversos exemplos ilustrando esses tópicos.

Também foi abordado o conceito de *independencia linear*, mais precisamente, dado um conjunto de vetores em latexmath:[$\mathbb{R}^n$], saber determinar se este é *linearmente independente* ou não;  se é uma *base* ou não de latexmath:[$\mathbb{R}^n$].

No próximo capítulo, estudaremos as noções básicas e necessárias sobre as *matrizes*, importante objeto de estudo deste livro, em particular dos capítulos 4 e 5.

 

////
Sempre termine os arquivos com uma linha em branco.
////
